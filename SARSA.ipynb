{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import gym \n",
    "import sys\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if \"../\" not in sys.path:\n",
    "  sys.path.append(\"../\") \n",
    "from lib.envs import plotting \n",
    "\n",
    "from collections import defaultdict\n",
    "from gym.envs.toy_text import discrete\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import namedtuple\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "EpisodeStats = namedtuple(\"Stats\",[\"episode_lengths\", \"episode_rewards\"])\n",
    "\n",
    "def plot_cost_to_go_mountain_car(env, estimator, num_tiles=20):\n",
    "    x = np.linspace(env.observation_space.low[0], env.observation_space.high[0], num=num_tiles)\n",
    "    y = np.linspace(env.observation_space.low[1], env.observation_space.high[1], num=num_tiles)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = np.apply_along_axis(lambda _: -np.max(estimator.predict(_)), 2, np.dstack([X, Y]))\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    surf = ax.plot_surface(X, Y, Z, rstride=1, cstride=1,\n",
    "                           cmap=matplotlib.cm.coolwarm, vmin=-1.0, vmax=1.0)\n",
    "    ax.set_xlabel('Position')\n",
    "    ax.set_ylabel('Velocity')\n",
    "    ax.set_zlabel('Value')\n",
    "    ax.set_title(\"Mountain \\\"Cost To Go\\\" Function\")\n",
    "    fig.colorbar(surf)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_value_function(V, title=\"Value Function\"):\n",
    "    \"\"\"\n",
    "    Plots the value function as a surface plot.\n",
    "    \"\"\"\n",
    "    min_x = min(k[0] for k in V.keys())\n",
    "    max_x = max(k[0] for k in V.keys())\n",
    "    min_y = min(k[1] for k in V.keys())\n",
    "    max_y = max(k[1] for k in V.keys())\n",
    "\n",
    "    x_range = np.arange(min_x, max_x + 1)\n",
    "    y_range = np.arange(min_y, max_y + 1)\n",
    "    X, Y = np.meshgrid(x_range, y_range)\n",
    "\n",
    "    # Find value for all (x, y) coordinates\n",
    "    Z_noace = np.apply_along_axis(lambda _: V[(_[0], _[1], False)], 2, np.dstack([X, Y]))\n",
    "    Z_ace = np.apply_along_axis(lambda _: V[(_[0], _[1], True)], 2, np.dstack([X, Y]))\n",
    "\n",
    "    def plot_surface(X, Y, Z, title):\n",
    "        fig = plt.figure(figsize=(20, 10))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        surf = ax.plot_surface(X, Y, Z, rstride=1, cstride=1,\n",
    "                               cmap=matplotlib.cm.coolwarm, vmin=-1.0, vmax=1.0)\n",
    "        ax.set_xlabel('Player Sum')\n",
    "        ax.set_ylabel('Dealer Showing')\n",
    "        ax.set_zlabel('Value')\n",
    "        ax.set_title(title)\n",
    "        ax.view_init(ax.elev, -120)\n",
    "        fig.colorbar(surf)\n",
    "        plt.show()\n",
    "\n",
    "    plot_surface(X, Y, Z_noace, \"{} (No Usable Ace)\".format(title))\n",
    "    plot_surface(X, Y, Z_ace, \"{} (Usable Ace)\".format(title))\n",
    "\n",
    "\n",
    "\n",
    "def plot_episode_stats(stats, smoothing_window=10, noshow=False):\n",
    "    # Plot the episode length over time\n",
    "    fig1 = plt.figure(figsize=(10,5))\n",
    "    plt.plot(stats.episode_lengths)\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Episode Length\")\n",
    "    plt.title(\"Episode Length over Time\")\n",
    "    if noshow:\n",
    "        plt.close(fig1)\n",
    "    else:\n",
    "        plt.show(fig1)\n",
    "\n",
    "    # Plot the episode reward over time\n",
    "    fig2 = plt.figure(figsize=(10,5))\n",
    "    rewards_smoothed = pd.Series(stats.episode_rewards).rolling(smoothing_window, min_periods=smoothing_window).mean()\n",
    "    plt.plot(rewards_smoothed)\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Episode Reward (Smoothed)\")\n",
    "    plt.title(\"Episode Reward over Time (Smoothed over window size {})\".format(smoothing_window))\n",
    "    if noshow:\n",
    "        plt.close(fig2)\n",
    "    else:\n",
    "        plt.show(fig2)\n",
    "\n",
    "    # Plot time steps and episode number\n",
    "    fig3 = plt.figure(figsize=(10,5))\n",
    "    plt.plot(np.cumsum(stats.episode_lengths), np.arange(len(stats.episode_lengths)))\n",
    "    plt.xlabel(\"Time Steps\")\n",
    "    plt.ylabel(\"Episode\")\n",
    "    plt.title(\"Episode per time step\")\n",
    "    if noshow:\n",
    "        plt.close(fig3)\n",
    "    else:\n",
    "        plt.show(fig3)\n",
    "\n",
    "    return fig1, fig2, fig3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "UP = 0\n",
    "RIGHT = 1\n",
    "DOWN = 2\n",
    "LEFT = 3\n",
    "\n",
    "class WindyGridworldEnv(discrete.DiscreteEnv):\n",
    "\n",
    "    metadata = {'render.modes': ['human', 'ansi']}\n",
    "\n",
    "    def _limit_coordinates(self, coord):\n",
    "        coord[0] = min(coord[0], self.shape[0] - 1)\n",
    "        coord[0] = max(coord[0], 0)\n",
    "        coord[1] = min(coord[1], self.shape[1] - 1)\n",
    "        coord[1] = max(coord[1], 0)\n",
    "        return coord\n",
    "\n",
    "    def _calculate_transition_prob(self, current, delta, winds):\n",
    "        new_position = np.array(current) + np.array(delta) + np.array([-1, 0]) * winds[tuple(current)]\n",
    "        new_position = self._limit_coordinates(new_position).astype(int)\n",
    "        new_state = np.ravel_multi_index(tuple(new_position), self.shape)\n",
    "        is_done = tuple(new_position) == (3, 7)\n",
    "        return [(1.0, new_state, -1.0, is_done)]\n",
    "\n",
    "    def __init__(self):\n",
    "        self.shape = (7, 10)\n",
    "\n",
    "        nS = np.prod(self.shape)\n",
    "        nA = 4\n",
    "\n",
    "        # Wind strength\n",
    "        winds = np.zeros(self.shape)\n",
    "        winds[:,[3,4,5,8]] = 1\n",
    "        winds[:,[6,7]] = 2\n",
    "\n",
    "        # Calculate transition probabilities\n",
    "        P = {}\n",
    "        for s in range(nS):\n",
    "            position = np.unravel_index(s, self.shape)\n",
    "            P[s] = { a : [] for a in range(nA) }\n",
    "            P[s][UP] = self._calculate_transition_prob(position, [-1, 0], winds)\n",
    "            P[s][RIGHT] = self._calculate_transition_prob(position, [0, 1], winds)\n",
    "            P[s][DOWN] = self._calculate_transition_prob(position, [1, 0], winds)\n",
    "            P[s][LEFT] = self._calculate_transition_prob(position, [0, -1], winds)\n",
    "\n",
    "        # We always start in state (3, 0)\n",
    "        isd = np.zeros(nS)\n",
    "        isd[np.ravel_multi_index((3,0), self.shape)] = 1.0\n",
    "\n",
    "        super(WindyGridworldEnv, self).__init__(nS, nA, P, isd)\n",
    "\n",
    "    def render(self, mode='human', close=False):\n",
    "        self._render(mode, close)\n",
    "\n",
    "    def _render(self, mode='human', close=False):\n",
    "        if close:\n",
    "            return\n",
    "\n",
    "        outfile = StringIO() if mode == 'ansi' else sys.stdout\n",
    "\n",
    "        for s in range(self.nS):\n",
    "            position = np.unravel_index(s, self.shape)\n",
    "            # print(self.s)\n",
    "            if self.s == s:\n",
    "                output = \" x \"\n",
    "            elif position == (3,7):\n",
    "                output = \" T \"\n",
    "            else:\n",
    "                output = \" o \"\n",
    "\n",
    "            if position[1] == 0:\n",
    "                output = output.lstrip()\n",
    "            if position[1] == self.shape[1] - 1:\n",
    "                output = output.rstrip()\n",
    "                output += \"\\n\"\n",
    "\n",
    "            outfile.write(output)\n",
    "        outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "x  o  o  o  o  o  o  T  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "\n",
      "(31, -1.0, False, {'prob': 1.0})\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  x  o  o  o  o  o  T  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "\n",
      "(32, -1.0, False, {'prob': 1.0})\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  x  o  o  o  o  T  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "\n",
      "(33, -1.0, False, {'prob': 1.0})\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  x  o  o  o  T  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "\n",
      "(33, -1.0, False, {'prob': 1.0})\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  x  o  o  o  T  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "\n",
      "(24, -1.0, False, {'prob': 1.0})\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  x  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  T  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "\n",
      "(15, -1.0, False, {'prob': 1.0})\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  x  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  T  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = WindyGridworldEnv()\n",
    "\n",
    "print(env.reset())\n",
    "env.render()\n",
    "\n",
    "print(env.step(1))\n",
    "env.render()\n",
    "\n",
    "print(env.step(1))\n",
    "env.render()\n",
    "\n",
    "print(env.step(1))\n",
    "env.render()\n",
    "\n",
    "print(env.step(2))\n",
    "env.render()\n",
    "\n",
    "print(env.step(1))\n",
    "env.render()\n",
    "\n",
    "print(env.step(1))\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_epsilon_greedy_policy(Q, epsilon, nA):\n",
    "    \"\"\"\n",
    "    Creates an epsilon-greedy policy based on a given Q-function and epsilon.\n",
    "    \n",
    "    Args:\n",
    "        Q: A dictionary that maps from state -> action-values.\n",
    "            Each value is a numpy array of length nA (see below)\n",
    "        epsilon: The probability to select a random action . float between 0 and 1.\n",
    "        nA: Number of actions in the environment.\n",
    "    \n",
    "    Returns:\n",
    "        A function that takes the observation as an argument and returns\n",
    "        the probabilities for each action in the form of a numpy array of length nA.\n",
    "    \n",
    "    \"\"\"\n",
    "    def policy_fn(observation):\n",
    "        A = np.ones(nA, dtype=float) * epsilon / nA\n",
    "        best_action = np.argmax(Q[observation])\n",
    "        A[best_action] += (1.0 - epsilon)\n",
    "        return A\n",
    "    return policy_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarsa(env, num_episodes, discount_factor=1.0, alpha=0.5, epsilon=0.1):\n",
    "    \"\"\"\n",
    "    SARSA algorithm: On-policy TD control. Finds the optimal epsilon-greedy policy.\n",
    "    \n",
    "    Args:\n",
    "        env: OpenAI environment.\n",
    "        num_episodes: Number of episodes to run for.\n",
    "        discount_factor: Gamma discount factor.\n",
    "        alpha: TD learning rate.\n",
    "        epsilon: Chance the sample a random action. Float betwen 0 and 1.\n",
    "    \n",
    "    Returns:\n",
    "        A tuple (Q, stats).\n",
    "        Q is the optimal action-value function, a dictionary mapping state -> action values.\n",
    "        stats is an EpisodeStats object with two numpy arrays for episode_lengths and episode_rewards.\n",
    "    \"\"\"\n",
    "    \n",
    "    # The final action-value function.\n",
    "    # A nested dictionary that maps state -> (action -> action-value).\n",
    "    Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "    \n",
    "    # Keeps track of useful statistics\n",
    "    stats = plotting.EpisodeStats(\n",
    "        episode_lengths=np.zeros(num_episodes),\n",
    "        episode_rewards=np.zeros(num_episodes))\n",
    "\n",
    "    # The policy we're following\n",
    "    policy = make_epsilon_greedy_policy(Q, epsilon, env.action_space.n)\n",
    "    \n",
    "\n",
    "    for i_episode in range(num_episodes):\n",
    "        # Print out which episode we're on, useful for debugging.\n",
    "        if (i_episode + 1) % 100 == 0:\n",
    "            print(\"\\rEpisode {}/{}.\".format(i_episode + 1, num_episodes), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "        # Implement this!\n",
    "    \n",
    "    return Q, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__new__() missing 1 required positional argument: 'episode_running_variance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-1495a45a793f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msarsa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-b2ac2783d2da>\u001b[0m in \u001b[0;36msarsa\u001b[0;34m(env, num_episodes, discount_factor, alpha, epsilon)\u001b[0m\n\u001b[1;32m     23\u001b[0m     stats = plotting.EpisodeStats(\n\u001b[1;32m     24\u001b[0m         \u001b[0mepisode_lengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         episode_rewards=np.zeros(num_episodes))\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# The policy we're following\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __new__() missing 1 required positional argument: 'episode_running_variance'"
     ]
    }
   ],
   "source": [
    "Q, stats = sarsa(env, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
